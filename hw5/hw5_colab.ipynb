{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-N3NIymK1DV"
   },
   "source": [
    "This notebook will follow previous notebooks in using Tensorboard, setting up, and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4CoO8AmIbmu"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "2_11Jd6VIeFP",
    "outputId": "72777b5a-4836-497f-d272-31d3b7211c81"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4AHokLZeGOzN",
    "outputId": "5b80548d-9e6c-4827-fe4c-978e984f201b"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvVpqHfiGP76"
   },
   "outputs": [],
   "source": [
    "import homework\n",
    "import homework.train\n",
    "import homework.language\n",
    "import homework.models as models\n",
    "import homework.utils as utils\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import importlib\n",
    "importlib.reload(homework.language);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 30, 23])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-140-2124753bf780>\", line 10, in <module>\n",
      "    tcn.forward(x).shape\n",
      "  File \"C:\\Users\\Owner\\Documents\\dl\\hw5\\homework\\models.py\", line 142, in forward\n",
      "    o = self.net(cat)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 541, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\Documents\\dl\\hw5\\homework\\models.py\", line 94, in forward\n",
      "    z = z + int(self.is_residual) * self.skip(x)\n",
      "RuntimeError: The size of tensor a (23) must match the size of tensor b (21) at non-singleton dimension 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Owner\\Anaconda37\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (23) must match the size of tensor b (21) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework.models);\n",
    "tcn = models.TCN()\n",
    "B = 9\n",
    "L = 20\n",
    "x = torch.zeros(B, 28, L)\n",
    "for b in range(B):\n",
    "    for l in range(L):\n",
    "        x[b, torch.randint(0,28,[1]).item(), l] = 1\n",
    "        \n",
    "tcn.forward(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = tcn.predict_all('abc')\n",
    "o = (o/o.sum(0))\n",
    "o.sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gF9SmorOGSsS"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "args = namedtuple('args', 'log_dir other_args')\n",
    "args.log_dir = 'log'\n",
    "args.other_args = 'something'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JJUYlgiHMF1"
   },
   "outputs": [],
   "source": [
    "model = homework.models.Bigram()\n",
    "max_length = 5555\n",
    "abc = 'abcdefghijklmnopqrstuvwxyz .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homework.language import TopNHeap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.1771"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.8606 + 2.8882 + 2.4283\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9897, -5.9865, -3.4648, -2.8643, -3.6430, -4.4269, -4.8329, -6.4725,\n",
       "        -4.4479, -7.9105, -6.3508, -3.5756, -3.9347, -2.4472, -4.7010, -4.6165,\n",
       "        -6.2422, -2.0728, -2.4283, -3.6112, -6.9841, -3.8502, -4.8117, -4.8071,\n",
       "        -4.4498, -8.6344, -1.0955, -4.0949])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.1770)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text = 'yes'\n",
    "ll_matrix = model.predict_all(some_text)[:,:-1]\n",
    "ll = (ll_matrix * homework.utils.one_hot(some_text)).sum()\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in yes\n",
      "out -9.177042007446289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-9.177042007446289"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = homework.language.log_likelihood\n",
    "bg = homework.models.Bigram()\n",
    "\n",
    "ll(bg, 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homework.models import LanguageModel\n",
    "class Dummy(LanguageModel):\n",
    "    def predict_all(self, text):\n",
    "        r = 1e-5*torch.ones(len(vocab), len(text)+1)\n",
    "        for i, s in enumerate(text):\n",
    "            r[(vocab.index(s)+1)%len(vocab), i+1] = 1\n",
    "        r[0, 0] = 2\n",
    "        r[1, 0] = 1\n",
    "        return (r/r.sum(dim=0, keepdim=True)).log()\n",
    "\n",
    "model = homework.models.Bigram()\n",
    "model = Dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-12.611624717712402, ' '), (-12.611624717712402, 'd'), (-12.611624717712402, '.'), (-12.611624717712402, 'h'), (-12.611624717712402, 'e'), (-12.611624717712402, 'f'), (-12.611624717712402, 'c'), (-12.611624717712402, 'p'), (-12.611624717712402, 'i'), (-12.611624717712402, 'j'), (-12.611624717712402, 'k'), (-12.611624717712402, 'x'), (-12.611624717712402, 'l'), (-12.611624717712402, 'g'), (-12.611624717712402, 'o'), (-12.611624717712402, 'q'), (-12.611624717712402, 'r'), (-12.611624717712402, 's'), (-12.611624717712402, 't'), (-12.611624717712402, 'u'), (-12.611624717712402, 'v'), (-12.611624717712402, 'w'), (-12.611624717712402, 'y'), (-12.611624717712402, 'z'), (-12.611624717712402, 'm'), (-12.611624717712402, 'n'), (-1.0986990928649902, 'b'), (-0.4055519104003906, 'a')]\n"
     ]
    }
   ],
   "source": [
    "max_length = 1\n",
    "average_log_likelihood = False\n",
    "n_results= 10\n",
    "beam_size = 100\n",
    "\n",
    "heap = TopNHeap(N=beam_size)\n",
    "vocab = 'abcdefghijklmnopqrstuvwxyz .'\n",
    "\n",
    "next_likes = model.predict_next('')\n",
    "for i, next_like in enumerate(next_likes):\n",
    "    element = ((next_like).item(), vocab[i])\n",
    "    if element not in [e[1] for e in heap.elements]:\n",
    "        heap.add(element)\n",
    "\n",
    "# for depth in range(max_length):        \n",
    "#     for like, string in heap.elements:\n",
    "#         if string[-1] == '.':\n",
    "#             continue\n",
    "#         next_likes = model.predict_next(string[-1])\n",
    "#         for i, next_like in enumerate(next_likes):\n",
    "#             if average_log_likelihood:\n",
    "#                 curr_len = len(string)\n",
    "#                 avg_like = (like*curr_len + next_like.item())/(curr_len + 1)\n",
    "#                 element = (avg_like, string + vocab[i])\n",
    "#             else:\n",
    "#                 element = ((like + next_like).item(), string + vocab[i])\n",
    "#             if element[1] not in [e[1] for e in heap.elements]:\n",
    "#                 heap.add(element)\n",
    "\n",
    "output = [e[1] for e in heap.elements[:n_results]]\n",
    "print(sorted(heap.elements, key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-487-8b0b075be763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhomework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhomework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\dl\\hw5\\homework\\models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     raise AttributeError(\n\u001b[1;32m--> 617\u001b[1;33m                         \"cannot assign module before Module.__init__() call\")\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[0mremove_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework.models)\n",
    "homework.models.TCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.273967107137044"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from homework.language import *\n",
    "import numpy as np\n",
    "importlib.reload(homework.language)\n",
    "ll = []\n",
    "for _ in range(100):\n",
    "    ll.append(log_likelihood(model, sample_random(model, 30))/30)\n",
    "np.median(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'homework.models' has no attribute 'dummy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-454-32e69d0dfec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhomework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'homework.models' has no attribute 'dummy'"
     ]
    }
   ],
   "source": [
    "homework.models.dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.2664398923516273, 'athe the the the the the the the'),\n",
       " (-1.2664147785731725, 'the thathe the the the the the the '),\n",
       " (-1.2662745714187624, 'the t the the the the the the the the the the'),\n",
       " (-1.2654581655155526,\n",
       "  'athe the the the the the the the the the the the the th'),\n",
       " (-1.2658779223759968, 'the'),\n",
       " (-1.2657688800245521,\n",
       "  'athe the the the the the the the the the the the the the the tha'),\n",
       " (-1.2657312676310537, 'the the the the the the the the the the the than'),\n",
       " (-1.265296931169471, 'the the the the the the the the the the the the a'),\n",
       " (-1.2654396828852204, 'the the the the the the the the the t '),\n",
       " (-1.2640593929110833,\n",
       "  'the the the the the the the the the the the the the a'),\n",
       " (-1.2657231069528139, 'the the the the the the the the the the the the ther'),\n",
       " (-1.2655600698097893, 'the thathe the the the the the the the the the'),\n",
       " (-1.2634965059084773, 'the the the the the the the the the tha'),\n",
       " (-1.2644365200629601, 'the the the the the the the the the the the the than'),\n",
       " (-1.2638644320624217, 'the the the the the the the the the the t '),\n",
       " (-1.2645214242594582,\n",
       "  'the the the the the the the the the the the the the ther'),\n",
       " (-1.2594355501626668, 'the the the the the the the the the th'),\n",
       " (-1.2629955442328202,\n",
       "  'the the the the the the the the the the the the the the a'),\n",
       " (-1.2652622584638922,\n",
       "  'athe the the the the the the the the the the the the the t'),\n",
       " (-1.263864432062422, 'the t the the the the the the the the the '),\n",
       " (-1.2619428051278947, 'the thathe the the the the the the the the the '),\n",
       " (-1.2654396828852206, 'the t the the the the the the the the '),\n",
       " (-1.2643355474633684,\n",
       "  'athe the the the the the the the the the the the the the th'),\n",
       " (-1.2648562022617884, 'the t the the the the the the the the the the the'),\n",
       " (-1.2651647295270647, 'the the the the the the the the tha'),\n",
       " (-1.2625631379044573, 'the the the the the the the the the the the t '),\n",
       " (-1.2622451504071555, 'the the the the the the the th'),\n",
       " (-1.2642065998046628,\n",
       "  'athe the the the the the the the the the the the the the the t'),\n",
       " (-1.2629664478630855, 'athe the the the the the the '),\n",
       " (-1.262931823730469, 'athe the the the the the the the the the'),\n",
       " (-1.2605931113163629, 'athe the the the the the the the the the the the'),\n",
       " (-1.2640264897510922, 'the the the the the the the t'),\n",
       " (-1.2633554840844772,\n",
       "  'athe the the the the the the the the the the the the the the th'),\n",
       " (-1.257224856590738, 'athe the the the the the the the the the the the '),\n",
       " (-1.2578522283203748, 'the the the the the the the the the the the the t'),\n",
       " (-1.256313772113235,\n",
       "  'the the the the the the the the the the the the the th'),\n",
       " (-1.2607557999121177, 'the the the the the the the the the t'),\n",
       " (-1.2652171516418458, 'athe the the the the the '),\n",
       " (-1.2644909653398726, 'athe the the the the the the the the'),\n",
       " (-1.2625631379044575, 'the t the the the the the the the the the the '),\n",
       " (-1.2621929212050005, 'the the the the the the the the t'),\n",
       " (-1.255175550167377,\n",
       "  'athe the the the the the the the the the the the the the the the '),\n",
       " (-1.2592501185157083,\n",
       "  'the the the the the the the the the the the the the tha'),\n",
       " (-1.2646183447960095, 'the thathe the the the the the the the '),\n",
       " (-1.2633267364331655,\n",
       "  'the the the the the the the the the the the the the than'),\n",
       " (-1.2642983198165894, 'the the the the the the th'),\n",
       " (-1.257964883910285, 'athe the the the the the the the the the the '),\n",
       " (-1.2631561312564583, 'the thathe the the the the the the the the '),\n",
       " (-1.2596936065417066, 'athe the the the the the the the the the the the the'),\n",
       " (-1.260675079682294, 'the the the the the the the the th'),\n",
       " (-1.2515803450032283, 'the the the the the'),\n",
       " (-1.2565957119590359,\n",
       "  'the the the the the the the the the the the the the the t'),\n",
       " (-1.2424985617399216, 'the the the the '),\n",
       " (-1.2616561624136837, 'athe the the the the the the the the the the'),\n",
       " (-1.2576032021771304, 'the the the the the the the the the the the th'),\n",
       " (-1.2452418420995985, 'the the the the the the the '),\n",
       " (-1.2499832751903126, 'the the the the the the the the the the the the'),\n",
       " (-1.2507860351491857, 'the the the the the the the'),\n",
       " (-1.2614700508117676, 'the the the the the the the the the the the the t '),\n",
       " (-1.2505426176132695, 'the the the the the the the the'),\n",
       " (-1.2498256423256613,\n",
       "  'the the the the the the the the the the the the the the'),\n",
       " (-1.2599249562701664, 'athe the the the the the the the the '),\n",
       " (-1.2586480220158893, 'the the the the the the the the the the the t'),\n",
       " (-1.2614700508117673, 'the t the the the the the the the the the the the '),\n",
       " (-1.2522952238718668, 'the the the the'),\n",
       " (-1.2511141196541165, 'the the the the the the'),\n",
       " (-1.2589226024491444,\n",
       "  'athe the the the the the the the the the the the the the'),\n",
       " (-1.2232955992221832, 'the '),\n",
       " (-1.2467658867438633, 'the the the the the the the the the the the the '),\n",
       " (-1.2470706956727164,\n",
       "  'the the the the the the the the the the the the the the '),\n",
       " (-1.2565965315081036,\n",
       "  'athe the the the the the the the the the the the the '),\n",
       " (-1.2360975742340088, 'the the '),\n",
       " (-1.245699055492878, 'the the the the the the the the '),\n",
       " (-1.2446322242418926, 'the the the the the the '),\n",
       " (-1.258432121503921, 'the the the the the the the the the the th'),\n",
       " (-1.2576697207987306,\n",
       "  'athe the the the the the the the the the the the the the the the'),\n",
       " (-1.2612613692428127, 'athe the the the the the the the '),\n",
       " (-1.258849306804378, 'athe the the the the the the the the the '),\n",
       " (-1.2595990925300413, 'the the the the the the the the the the t'),\n",
       " (-1.2610119175403673, 'the the the the the the the the the the the tha'),\n",
       " (-1.2463391542434694, 'the the the the the the the the the the '),\n",
       " (-1.2503548383712768, 'the the the the the the the the the'),\n",
       " (-1.2500840869060783, 'the the the the the the the the the the the'),\n",
       " (-1.2535300146449695, 'the the the'),\n",
       " (-1.2502055779481547, 'the the the the the the the the the the'),\n",
       " (-1.2555870912114124,\n",
       "  'athe the the the the the the the the the the the the the the '),\n",
       " (-1.2403648992379506, 'the the the '),\n",
       " (-1.246054665909873, 'the the the the the the the the the '),\n",
       " (-1.2605389025476244,\n",
       "  'the the the the the the the the the the the the the t '),\n",
       " (-1.2560563924019794,\n",
       "  'athe the the the the the the the the the the the the the '),\n",
       " (-1.2569069099426269, 'the the the the the the the the the the the the th'),\n",
       " (-1.258254398902257,\n",
       "  'athe the the the the the the the the the the the the the the'),\n",
       " (-1.260061927870208, 'the the the the the the the the the the the the tha'),\n",
       " (-1.2465719174255023, 'the the the the the the the the the the the '),\n",
       " (-1.243778759241104, 'the the the the the '),\n",
       " (-1.2561759948730469, 'the the'),\n",
       " (-1.2621386494747429, 'the the the the the the the the the the tha'),\n",
       " (-1.2571765544279567,\n",
       "  'the the the the the the the the the the the the the t'),\n",
       " (-1.2469300146286304, 'the the the the the the the the the the the the the '),\n",
       " (-1.2498982770770204, 'the the the the the the the the the the the the the')]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heap.elements"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dl_class_hw5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
