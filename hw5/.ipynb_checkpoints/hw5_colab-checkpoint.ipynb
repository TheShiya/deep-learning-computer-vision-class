{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-N3NIymK1DV"
   },
   "source": [
    "This notebook will follow previous notebooks in using Tensorboard, setting up, and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4CoO8AmIbmu"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "2_11Jd6VIeFP",
    "outputId": "72777b5a-4836-497f-d272-31d3b7211c81"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4AHokLZeGOzN",
    "outputId": "5b80548d-9e6c-4827-fe4c-978e984f201b"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvVpqHfiGP76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'homework.language' from 'C:\\\\Users\\\\Owner\\\\Documents\\\\dl\\\\hw5\\\\homework\\\\language.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import homework\n",
    "import homework.train\n",
    "import homework.language\n",
    "import homework.models as models\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import importlib\n",
    "importlib.reload(homework.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6860,  0.2768, -1.6774,  ..., -0.0424, -0.4658,  0.0138],\n",
       "         [-0.3771, -1.1027, -0.5430,  ..., -0.5388,  0.7318,  0.1845],\n",
       "         [-1.6361,  1.1947,  0.7925,  ...,  2.2887,  1.6223,  0.0428],\n",
       "         ...,\n",
       "         [ 1.4436, -0.0058, -0.3988,  ..., -0.4229,  0.3648,  1.1484],\n",
       "         [ 0.8660, -0.6314, -1.0797,  ...,  0.2607, -0.8860, -1.2048],\n",
       "         [-0.4258, -0.3988,  1.0735,  ..., -1.9788,  0.9892, -0.2430]],\n",
       "\n",
       "        [[-1.9499, -0.0965,  1.1998,  ...,  0.9510, -0.4465,  0.9622],\n",
       "         [ 1.7824,  1.6864, -0.8829,  ...,  0.6151, -0.3698, -1.0738],\n",
       "         [ 1.7796,  0.0234, -1.0074,  ...,  0.0377, -0.1682, -1.1366],\n",
       "         ...,\n",
       "         [-0.0587, -1.0156,  0.1771,  ..., -0.3578, -0.8624,  1.1342],\n",
       "         [-0.4302, -1.5868, -0.1119,  ..., -0.1993, -0.1686, -0.5120],\n",
       "         [-0.4121,  1.3892, -0.7249,  ...,  1.8817,  1.0080, -0.8293]],\n",
       "\n",
       "        [[ 0.0245, -0.6094, -0.0992,  ..., -0.0334, -1.8591, -0.3628],\n",
       "         [-1.4072,  0.8640, -1.2455,  ..., -0.4275, -0.2724,  1.7421],\n",
       "         [ 0.2987,  0.8893,  0.0580,  ...,  1.1479, -0.4853,  0.9107],\n",
       "         ...,\n",
       "         [-2.5244, -1.3499, -0.4296,  ...,  0.5989,  0.0430,  0.8119],\n",
       "         [ 1.4010,  0.8233,  1.7066,  ..., -0.6835, -0.8536,  0.9390],\n",
       "         [ 1.0805, -0.8405, -1.8595,  ..., -0.2186, -0.6332, -0.2501]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4558, -0.2025, -0.5248,  ...,  0.4763,  0.7289,  0.4505],\n",
       "         [-0.1208, -1.1865,  0.5895,  ...,  0.0053, -0.0186,  0.4128],\n",
       "         [-0.5358, -0.5618,  0.6198,  ..., -0.4537, -0.2807,  0.0466],\n",
       "         ...,\n",
       "         [-0.4456, -2.3414, -2.2283,  ...,  1.7895,  0.6729, -0.1816],\n",
       "         [ 0.3764, -0.2429, -0.6183,  ..., -0.3716,  1.4945, -0.4573],\n",
       "         [-0.5161,  1.0020, -0.4837,  ..., -0.3188, -0.5196,  0.6131]],\n",
       "\n",
       "        [[ 0.3025,  1.5608,  0.1459,  ..., -1.5167, -0.6436, -0.5090],\n",
       "         [ 1.6477,  1.0883, -1.0327,  ...,  0.6310, -1.5089, -0.5265],\n",
       "         [-0.9250,  0.6270,  1.3378,  ...,  0.6804,  1.5001,  1.9601],\n",
       "         ...,\n",
       "         [-0.4309,  0.8954, -1.6378,  ..., -0.1556,  2.6213, -0.4315],\n",
       "         [ 0.4334,  1.2599,  1.6423,  ...,  1.2927, -0.7756,  0.6434],\n",
       "         [-0.8382, -1.2475, -1.0814,  ..., -0.6009,  0.2607, -0.1493]],\n",
       "\n",
       "        [[-0.2507,  1.1779,  0.1825,  ...,  1.3831,  1.7627,  1.0251],\n",
       "         [-0.1736, -0.4918, -1.8060,  ...,  1.2477, -0.2316, -2.1643],\n",
       "         [-1.6762, -0.2617,  0.6769,  ...,  1.6573,  0.3606,  1.1224],\n",
       "         ...,\n",
       "         [ 2.1492, -0.7849, -2.2540,  ...,  0.4749, -0.0873, -1.1177],\n",
       "         [-0.8264, -0.5389, -0.5410,  ..., -2.5869,  1.4133, -0.8539],\n",
       "         [-1.0261,  0.5280,  0.3393,  ..., -0.7452, -1.0527, -1.6767]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcn = models.TCN()\n",
    "B = 9\n",
    "L = 20\n",
    "x = torch.zeros(B, 28, L)\n",
    "for b in range(B):\n",
    "    for l in range(L):\n",
    "        x[b, torch.randint(0,28,[1]).item(), l] = 1\n",
    "        \n",
    "tcn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gF9SmorOGSsS"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "args = namedtuple('args', 'log_dir other_args')\n",
    "args.log_dir = 'log'\n",
    "args.other_args = 'something'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JJUYlgiHMF1"
   },
   "outputs": [],
   "source": [
    "model = homework.models.Bigram()\n",
    "max_length = 5555\n",
    "abc = 'abcdefghijklmnopqrstuvwxyz .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homework.language import TopNHeap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.1771"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.8606 + 2.8882 + 2.4283\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9897, -5.9865, -3.4648, -2.8643, -3.6430, -4.4269, -4.8329, -6.4725,\n",
       "        -4.4479, -7.9105, -6.3508, -3.5756, -3.9347, -2.4472, -4.7010, -4.6165,\n",
       "        -6.2422, -2.0728, -2.4283, -3.6112, -6.9841, -3.8502, -4.8117, -4.8071,\n",
       "        -4.4498, -8.6344, -1.0955, -4.0949])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_next('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.1770)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text = 'yes'\n",
    "ll_matrix = model.predict_all(some_text)[:,:-1]\n",
    "ll = (ll_matrix * homework.utils.one_hot(some_text)).sum()\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in yes\n",
      "out -9.177042007446289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-9.177042007446289"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = homework.language.log_likelihood\n",
    "bg = homework.models.Bigram()\n",
    "\n",
    "ll(bg, 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homework.models import LanguageModel\n",
    "class Dummy(LanguageModel):\n",
    "    def predict_all(self, text):\n",
    "        r = 1e-5*torch.ones(len(vocab), len(text)+1)\n",
    "        for i, s in enumerate(text):\n",
    "            r[(vocab.index(s)+1)%len(vocab), i+1] = 1\n",
    "        r[0, 0] = 2\n",
    "        r[1, 0] = 1\n",
    "        return (r/r.sum(dim=0, keepdim=True)).log()\n",
    "\n",
    "model = homework.models.Bigram()\n",
    "model = Dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-12.611624717712402, ' '), (-12.611624717712402, 'd'), (-12.611624717712402, '.'), (-12.611624717712402, 'h'), (-12.611624717712402, 'e'), (-12.611624717712402, 'f'), (-12.611624717712402, 'c'), (-12.611624717712402, 'p'), (-12.611624717712402, 'i'), (-12.611624717712402, 'j'), (-12.611624717712402, 'k'), (-12.611624717712402, 'x'), (-12.611624717712402, 'l'), (-12.611624717712402, 'g'), (-12.611624717712402, 'o'), (-12.611624717712402, 'q'), (-12.611624717712402, 'r'), (-12.611624717712402, 's'), (-12.611624717712402, 't'), (-12.611624717712402, 'u'), (-12.611624717712402, 'v'), (-12.611624717712402, 'w'), (-12.611624717712402, 'y'), (-12.611624717712402, 'z'), (-12.611624717712402, 'm'), (-12.611624717712402, 'n'), (-1.0986990928649902, 'b'), (-0.4055519104003906, 'a')]\n"
     ]
    }
   ],
   "source": [
    "max_length = 1\n",
    "average_log_likelihood = False\n",
    "n_results= 10\n",
    "beam_size = 100\n",
    "\n",
    "heap = TopNHeap(N=beam_size)\n",
    "vocab = 'abcdefghijklmnopqrstuvwxyz .'\n",
    "\n",
    "next_likes = model.predict_next('')\n",
    "for i, next_like in enumerate(next_likes):\n",
    "    element = ((next_like).item(), vocab[i])\n",
    "    if element not in [e[1] for e in heap.elements]:\n",
    "        heap.add(element)\n",
    "\n",
    "# for depth in range(max_length):        \n",
    "#     for like, string in heap.elements:\n",
    "#         if string[-1] == '.':\n",
    "#             continue\n",
    "#         next_likes = model.predict_next(string[-1])\n",
    "#         for i, next_like in enumerate(next_likes):\n",
    "#             if average_log_likelihood:\n",
    "#                 curr_len = len(string)\n",
    "#                 avg_like = (like*curr_len + next_like.item())/(curr_len + 1)\n",
    "#                 element = (avg_like, string + vocab[i])\n",
    "#             else:\n",
    "#                 element = ((like + next_like).item(), string + vocab[i])\n",
    "#             if element[1] not in [e[1] for e in heap.elements]:\n",
    "#                 heap.add(element)\n",
    "\n",
    "output = [e[1] for e in heap.elements[:n_results]]\n",
    "print(sorted(heap.elements, key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-487-8b0b075be763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhomework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhomework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\dl\\hw5\\homework\\models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                     raise AttributeError(\n\u001b[1;32m--> 617\u001b[1;33m                         \"cannot assign module before Module.__init__() call\")\n\u001b[0m\u001b[0;32m    618\u001b[0m                 \u001b[0mremove_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework.models)\n",
    "homework.models.TCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.273967107137044"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from homework.language import *\n",
    "import numpy as np\n",
    "importlib.reload(homework.language)\n",
    "ll = []\n",
    "for _ in range(100):\n",
    "    ll.append(log_likelihood(model, sample_random(model, 30))/30)\n",
    "np.median(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'homework.models' has no attribute 'dummy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-454-32e69d0dfec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhomework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'homework.models' has no attribute 'dummy'"
     ]
    }
   ],
   "source": [
    "homework.models.dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.2664398923516273, 'athe the the the the the the the'),\n",
       " (-1.2664147785731725, 'the thathe the the the the the the '),\n",
       " (-1.2662745714187624, 'the t the the the the the the the the the the'),\n",
       " (-1.2654581655155526,\n",
       "  'athe the the the the the the the the the the the the th'),\n",
       " (-1.2658779223759968, 'the'),\n",
       " (-1.2657688800245521,\n",
       "  'athe the the the the the the the the the the the the the the tha'),\n",
       " (-1.2657312676310537, 'the the the the the the the the the the the than'),\n",
       " (-1.265296931169471, 'the the the the the the the the the the the the a'),\n",
       " (-1.2654396828852204, 'the the the the the the the the the t '),\n",
       " (-1.2640593929110833,\n",
       "  'the the the the the the the the the the the the the a'),\n",
       " (-1.2657231069528139, 'the the the the the the the the the the the the ther'),\n",
       " (-1.2655600698097893, 'the thathe the the the the the the the the the'),\n",
       " (-1.2634965059084773, 'the the the the the the the the the tha'),\n",
       " (-1.2644365200629601, 'the the the the the the the the the the the the than'),\n",
       " (-1.2638644320624217, 'the the the the the the the the the the t '),\n",
       " (-1.2645214242594582,\n",
       "  'the the the the the the the the the the the the the ther'),\n",
       " (-1.2594355501626668, 'the the the the the the the the the th'),\n",
       " (-1.2629955442328202,\n",
       "  'the the the the the the the the the the the the the the a'),\n",
       " (-1.2652622584638922,\n",
       "  'athe the the the the the the the the the the the the the t'),\n",
       " (-1.263864432062422, 'the t the the the the the the the the the '),\n",
       " (-1.2619428051278947, 'the thathe the the the the the the the the the '),\n",
       " (-1.2654396828852206, 'the t the the the the the the the the '),\n",
       " (-1.2643355474633684,\n",
       "  'athe the the the the the the the the the the the the the th'),\n",
       " (-1.2648562022617884, 'the t the the the the the the the the the the the'),\n",
       " (-1.2651647295270647, 'the the the the the the the the tha'),\n",
       " (-1.2625631379044573, 'the the the the the the the the the the the t '),\n",
       " (-1.2622451504071555, 'the the the the the the the th'),\n",
       " (-1.2642065998046628,\n",
       "  'athe the the the the the the the the the the the the the the t'),\n",
       " (-1.2629664478630855, 'athe the the the the the the '),\n",
       " (-1.262931823730469, 'athe the the the the the the the the the'),\n",
       " (-1.2605931113163629, 'athe the the the the the the the the the the the'),\n",
       " (-1.2640264897510922, 'the the the the the the the t'),\n",
       " (-1.2633554840844772,\n",
       "  'athe the the the the the the the the the the the the the the th'),\n",
       " (-1.257224856590738, 'athe the the the the the the the the the the the '),\n",
       " (-1.2578522283203748, 'the the the the the the the the the the the the t'),\n",
       " (-1.256313772113235,\n",
       "  'the the the the the the the the the the the the the th'),\n",
       " (-1.2607557999121177, 'the the the the the the the the the t'),\n",
       " (-1.2652171516418458, 'athe the the the the the '),\n",
       " (-1.2644909653398726, 'athe the the the the the the the the'),\n",
       " (-1.2625631379044575, 'the t the the the the the the the the the the '),\n",
       " (-1.2621929212050005, 'the the the the the the the the t'),\n",
       " (-1.255175550167377,\n",
       "  'athe the the the the the the the the the the the the the the the '),\n",
       " (-1.2592501185157083,\n",
       "  'the the the the the the the the the the the the the tha'),\n",
       " (-1.2646183447960095, 'the thathe the the the the the the the '),\n",
       " (-1.2633267364331655,\n",
       "  'the the the the the the the the the the the the the than'),\n",
       " (-1.2642983198165894, 'the the the the the the th'),\n",
       " (-1.257964883910285, 'athe the the the the the the the the the the '),\n",
       " (-1.2631561312564583, 'the thathe the the the the the the the the '),\n",
       " (-1.2596936065417066, 'athe the the the the the the the the the the the the'),\n",
       " (-1.260675079682294, 'the the the the the the the the th'),\n",
       " (-1.2515803450032283, 'the the the the the'),\n",
       " (-1.2565957119590359,\n",
       "  'the the the the the the the the the the the the the the t'),\n",
       " (-1.2424985617399216, 'the the the the '),\n",
       " (-1.2616561624136837, 'athe the the the the the the the the the the'),\n",
       " (-1.2576032021771304, 'the the the the the the the the the the the th'),\n",
       " (-1.2452418420995985, 'the the the the the the the '),\n",
       " (-1.2499832751903126, 'the the the the the the the the the the the the'),\n",
       " (-1.2507860351491857, 'the the the the the the the'),\n",
       " (-1.2614700508117676, 'the the the the the the the the the the the the t '),\n",
       " (-1.2505426176132695, 'the the the the the the the the'),\n",
       " (-1.2498256423256613,\n",
       "  'the the the the the the the the the the the the the the'),\n",
       " (-1.2599249562701664, 'athe the the the the the the the the '),\n",
       " (-1.2586480220158893, 'the the the the the the the the the the the t'),\n",
       " (-1.2614700508117673, 'the t the the the the the the the the the the the '),\n",
       " (-1.2522952238718668, 'the the the the'),\n",
       " (-1.2511141196541165, 'the the the the the the'),\n",
       " (-1.2589226024491444,\n",
       "  'athe the the the the the the the the the the the the the'),\n",
       " (-1.2232955992221832, 'the '),\n",
       " (-1.2467658867438633, 'the the the the the the the the the the the the '),\n",
       " (-1.2470706956727164,\n",
       "  'the the the the the the the the the the the the the the '),\n",
       " (-1.2565965315081036,\n",
       "  'athe the the the the the the the the the the the the '),\n",
       " (-1.2360975742340088, 'the the '),\n",
       " (-1.245699055492878, 'the the the the the the the the '),\n",
       " (-1.2446322242418926, 'the the the the the the '),\n",
       " (-1.258432121503921, 'the the the the the the the the the the th'),\n",
       " (-1.2576697207987306,\n",
       "  'athe the the the the the the the the the the the the the the the'),\n",
       " (-1.2612613692428127, 'athe the the the the the the the '),\n",
       " (-1.258849306804378, 'athe the the the the the the the the the '),\n",
       " (-1.2595990925300413, 'the the the the the the the the the the t'),\n",
       " (-1.2610119175403673, 'the the the the the the the the the the the tha'),\n",
       " (-1.2463391542434694, 'the the the the the the the the the the '),\n",
       " (-1.2503548383712768, 'the the the the the the the the the'),\n",
       " (-1.2500840869060783, 'the the the the the the the the the the the'),\n",
       " (-1.2535300146449695, 'the the the'),\n",
       " (-1.2502055779481547, 'the the the the the the the the the the'),\n",
       " (-1.2555870912114124,\n",
       "  'athe the the the the the the the the the the the the the the '),\n",
       " (-1.2403648992379506, 'the the the '),\n",
       " (-1.246054665909873, 'the the the the the the the the the '),\n",
       " (-1.2605389025476244,\n",
       "  'the the the the the the the the the the the the the t '),\n",
       " (-1.2560563924019794,\n",
       "  'athe the the the the the the the the the the the the the '),\n",
       " (-1.2569069099426269, 'the the the the the the the the the the the the th'),\n",
       " (-1.258254398902257,\n",
       "  'athe the the the the the the the the the the the the the the'),\n",
       " (-1.260061927870208, 'the the the the the the the the the the the the tha'),\n",
       " (-1.2465719174255023, 'the the the the the the the the the the the '),\n",
       " (-1.243778759241104, 'the the the the the '),\n",
       " (-1.2561759948730469, 'the the'),\n",
       " (-1.2621386494747429, 'the the the the the the the the the the tha'),\n",
       " (-1.2571765544279567,\n",
       "  'the the the the the the the the the the the the the t'),\n",
       " (-1.2469300146286304, 'the the the the the the the the the the the the the '),\n",
       " (-1.2498982770770204, 'the the the the the the the the the the the the the')]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heap.elements"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dl_class_hw5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
